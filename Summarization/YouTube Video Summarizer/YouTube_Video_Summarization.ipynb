{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcf8103c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import validators\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_classic.chains.summarize import load_summarize_chain\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30633226",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=os.getenv('GROQ_API_KEY')\n",
    "llm_model=ChatGroq(groq_api_key=api_key,model=\"openai/gpt-oss-20b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f685b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Template=\"\"\"\n",
    "Provide the consize summary of the content in 300 words:\n",
    "Content:{text}\n",
    "\"\"\"\n",
    "llm_prompt=PromptTemplate(template=Template,input_variables=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ef57fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary (≈300 words)**  \n",
      "\n",
      "The narrative traces the evolution of configuration and data‑exchange formats, highlighting how each emerged to meet shifting needs. It starts with **INI files**, simple key‑value pairs grouped into sections that remain ubiquitous on Windows due to their straightforward, non‑verbose nature. **XML** followed, offering structured validation and deep hierarchies, becoming the backbone of early web services and SOAP APIs. However, XML’s verbosity—numerous tags and strict syntax—proved cumbersome for developers. **JSON** then rose to prominence; its lightweight, readable syntax struck a balance between structure and simplicity, quickly becoming the de‑facto standard for APIs and web data. As systems grew, developers sought even more human‑friendly formats, leading to **YAML**. YAML’s indentation and minimal punctuation made it ideal for configuration and CI/CD pipelines, yet its reliance on whitespace introduced brittleness: a single mis‑indentation could break parsing.\n",
      "\n",
      "The core of the discussion shifts to **JSON’s limitations when communicating with large language models (LLMs)**. Three key issues are identified:\n",
      "\n",
      "1. **Verbosity** – braces, quotes, commas, and newlines each become separate tokens, inflating cost and latency.\n",
      "2. **Repetitive field names** – repeated keys add unnecessary tokens.\n",
      "3. **Model friendliness** – nested JSON structures are unnatural for token‑by‑token processing, causing hallucinations or format errors when a single bracket is missing.\n",
      "\n",
      "Enter **Tune** (pronounced “tune”), a token‑oriented object notation specifically engineered for LLMs. Tune eliminates superfluous punctuation, quotes, and repeated keys, representing data in a compact, table‑like form with a single header definition followed by raw values. This design aligns with how LLMs interpret patterns and lists, reducing token count by 30–60 % and lowering inference cost and hallucination risk. Tune’s syntax is indentation‑based like YAML but incorporates a concise array declaration that keeps structure minimal yet clear.\n",
      "\n",
      "The article cautions that Tune excels with clean, uniform arrays of objects but may be less efficient for deeply nested or semi‑uniform data, where compact JSON or even CSV might be preferable. Benchmarks show Tune outperforming other formats in token efficiency for AI‑centric workloads. The conclusion poses an open question: will Tune supplant JSON in LLM workflows, coexist alongside it, or fade away? The piece invites readers to weigh in, emphasizing Tune’s promise as a potential new standard for generative‑AI communication.\n"
     ]
    }
   ],
   "source": [
    "yt_url=input('Enter the URL :')\n",
    "try:\n",
    "    if validators.url(yt_url.strip()) and 'youtube.com' in yt_url:\n",
    "            loader=YoutubeLoader.from_youtube_url(yt_url,add_video_info=False)\n",
    "            docs=loader.load()\n",
    "            llm_chain=load_summarize_chain(llm=llm_model,chain_type='stuff',prompt=llm_prompt)\n",
    "            summary=llm_chain.invoke({'input_documents':docs})\n",
    "            print(summary['output_text'])\n",
    "    else:\n",
    "          print('Enter a valid URL')\n",
    "except:\n",
    "      print('Error occured')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31764c11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
