{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da6eedcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import bs4\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8acb4681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x107f17820>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x12ff0d3f0>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['HF_API_KEY']=os.getenv('HF_API_KEY')\n",
    "Groq_api_key=os.getenv('GROQ_API_KEY')\n",
    "\n",
    "llm_model=ChatGroq(groq_api_key=Groq_api_key,model_name=\"llama-3.3-70b-versatile\")\n",
    "llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cfb1d609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "Embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca1c1aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = WebBaseLoader(\"https://www.ibm.com/think/topics/ai-agents\")\n",
    "\n",
    "docs = loader.load()\n",
    "#print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "014e5b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = docs[0].page_content\n",
    "\n",
    "# removing blank lines\n",
    "cleaned_text = re.sub(r\"\\n\\s*\\n+\", \"\\n\", raw)\n",
    "cleaned_text= re.sub(r\"[ \\t]+\", \" \", cleaned_text)\n",
    "cleaned_text = cleaned_text.strip()\n",
    "\n",
    "#print(cleaned_text[::])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4fd5873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=250)\n",
    "splitted_text=text_splitter.split_text(cleaned_text)\n",
    "#splitted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4514f5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x12ff0de70>, search_kwargs={})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db=Chroma.from_texts(splitted_text,embedding=Embeddings)\n",
    "retriever=vector_db.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "518cc43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating System Prompt\n",
    "System_prompt = (\n",
    "    \"Answer the question using the provided context. \"\n",
    "    \"If unsure, say you don't know. \"\n",
    "    \"Limit your response to three concise sentences.\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "LLM_Prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",System_prompt),\n",
    "        ('human','{input}'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f03edb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain=create_stuff_documents_chain(llm_model,LLM_Prompt)\n",
    "rag_chain=create_retrieval_chain(retriever,question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15c07a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'what are ai agents?',\n",
       " 'context': [Document(id='52836ccb-e3a4-4dfe-b54e-0ef99810c551', metadata={}, page_content='AI agents\\n What are AI agents?\\nFrom monolithic models to compound AI systems, discover how AI agents integrate with databases and external tools to enhance problem-solving capabilities and adaptability.\\nLearn more\\n Reasoning paradigms\\r\\nThere is not one standard architecture for building AI agents. Several paradigms exist for solving multistep problems.\\nReAct (reasoning and action)\\nWith the ReAct paradigm, we can instruct agents to \"think\" and plan after each action taken and with each tool response to decide which tool to use next. These Think-Act-Observe loops are used to solve problems step by step and iteratively improve upon responses.\\nThrough the prompt structure, agents can be instructed to reason slowly and to display each \"thought\".4\\xa0The agent\\'s verbal reasoning gives insight into how responses are formulated. In this framework, agents continuously update their context with new reasoning. This approach can be interpreted as a form of\\xa0Chain-of-Thought prompting.'),\n",
       "  Document(id='559aa91d-b07e-450c-850c-f46f49c6a9c9', metadata={}, page_content='AI agents\\n What are AI agents?\\nFrom monolithic models to compound AI systems, discover how AI agents integrate with databases and external tools to enhance problem-solving capabilities and adaptability.\\nLearn more\\n Reasoning paradigms\\r\\nThere is not one standard architecture for building AI agents. Several paradigms exist for solving multistep problems.\\nReAct (reasoning and action)\\nWith the ReAct paradigm, we can instruct agents to \"think\" and plan after each action taken and with each tool response to decide which tool to use next. These Think-Act-Observe loops are used to solve problems step by step and iteratively improve upon responses.\\nThrough the prompt structure, agents can be instructed to reason slowly and to display each \"thought\".4\\xa0The agent\\'s verbal reasoning gives insight into how responses are formulated. In this framework, agents continuously update their context with new reasoning. This approach can be interpreted as a form of\\xa0Chain-of-Thought prompting.'),\n",
       "  Document(id='b6cccfaa-cc13-4164-865f-8abd98aa8f8c', metadata={}, page_content='2 Yonadov Shavit, Sandhini Agarwal, Miles Brundage, Steven Adler, Cullen O’Keefe, Rosie Campbell, Teddy Lee, Pamela Mishkin, Tyna Eloundou, Alan Hickey, Katarina Slama, Lama Ahmad, Paul McMillan, Alex Beutel, Alexandre Passos and David G. Robinson, “Practices for governing agentic AI Systems,”\\xa0OpenAI, 2023,\\xa0https://arxiv.org/pdf/2401.13138v3\\r\\n3 Tula Masterman, Sandi Besen, Mason Sawtell and Alex Chao, “The landscape of emerging AI agent architectures for reasoning, planning and tool calling: A Survey”\\xa0arXiv preprint, 2024,\\xa0https://arxiv.org/abs/2404.11584\\r\\n4 Gautier Dagan, Frank Keller and Alex Lascarides, \"Dynamic planning with an LLM,\" arXiv preprint, 2023\\xa0https://arxiv.org/abs/2308.06391\\r\\n5 Binfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu and Dongkuan Xu, \"ReWOO: Decoupling reasoning from observations for efficient augmented language models,\" arXiv preprint, 2023\\xa0https://arxiv.org/abs/2305.18323'),\n",
       "  Document(id='107a5d28-f0c8-4b77-ae65-98024798644f', metadata={}, page_content='2 Yonadov Shavit, Sandhini Agarwal, Miles Brundage, Steven Adler, Cullen O’Keefe, Rosie Campbell, Teddy Lee, Pamela Mishkin, Tyna Eloundou, Alan Hickey, Katarina Slama, Lama Ahmad, Paul McMillan, Alex Beutel, Alexandre Passos and David G. Robinson, “Practices for governing agentic AI Systems,”\\xa0OpenAI, 2023,\\xa0https://arxiv.org/pdf/2401.13138v3\\r\\n3 Tula Masterman, Sandi Besen, Mason Sawtell and Alex Chao, “The landscape of emerging AI agent architectures for reasoning, planning and tool calling: A Survey”\\xa0arXiv preprint, 2024,\\xa0https://arxiv.org/abs/2404.11584\\r\\n4 Gautier Dagan, Frank Keller and Alex Lascarides, \"Dynamic planning with an LLM,\" arXiv preprint, 2023\\xa0https://arxiv.org/abs/2308.06391\\r\\n5 Binfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu and Dongkuan Xu, \"ReWOO: Decoupling reasoning from observations for efficient augmented language models,\" arXiv preprint, 2023\\xa0https://arxiv.org/abs/2305.18323')],\n",
       " 'answer': 'AI agents are artificial intelligence systems that integrate with databases and external tools to enhance problem-solving capabilities and adaptability. They can be built using various architectures and paradigms, such as the ReAct paradigm, to solve multistep problems. AI agents can \"think\" and plan after each action taken, using Think-Act-Observe loops to iteratively improve upon responses.'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=rag_chain.invoke({'input':'what are ai agents?'})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49e44cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI agents are artificial intelligence systems that integrate with databases and external tools to enhance problem-solving capabilities and adaptability. They can be built using various architectures and paradigms, such as the ReAct paradigm, to solve multistep problems. AI agents can \"think\" and plan after each action taken, using Think-Act-Observe loops to iteratively improve upon responses.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5f2c8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AI agent is designed to assist a user in planning their surfing trip in Greece by predicting the best week for optimal surfing conditions. To achieve this, the agent gathers information from external databases and communicates with specialized agents to learn about ideal weather conditions, which include high tides, sunny weather, and minimal rain. The agent then combines this information to identify patterns and make a prediction, which is presented to the user, and subsequently refined through feedback mechanisms to improve its performance and adapt to user preferences.\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke({'input':'describe more about it'})['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94e73075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReWOO (reasoning without observation) is a method that eliminates the dependence on tool outputs for action planning, allowing agents to plan upfront and avoid redundant tool usage. This approach involves anticipating which tools to use upon receiving a user's prompt and planning ahead to reduce token usage and computational complexity. ReWOO is desirable from a human-centered perspective as it allows users to confirm the plan before it is executed.\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke({'input':'What is ReWoo'})['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f29b3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AI agent is designed to assist a user in planning their surfing trip to Greece by predicting the best week for surfing based on weather conditions. The agent gathers information from external databases and specialized agents to learn about optimal surfing conditions, such as high tides and sunny weather with little rain. The agent then combines this information to make a prediction and presents it to the user, while also using feedback mechanisms to improve its accuracy and adjust to user preferences for future goals.\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke({'input':'describe more about it'})['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bfdd0da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2778a264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Rewrite the user’s latest question so it can be understood on its own, \"\n",
    "    \"without relying on prior chat history. Include any necessary context from \"\n",
    "    \"the conversation. Do NOT answer the question—only reformulate it.\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt= ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system',contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder('chat_history'),\n",
    "        ('human','{input}'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3eca04bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x12ff0de70>, search_kwargs={}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x10e356ef0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Rewrite the user’s latest question so it can be understood on its own, without relying on prior chat history. Include any necessary context from the conversation. Do NOT answer the question—only reformulate it.'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x107f17820>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x12ff0d3f0>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x12ff0de70>, search_kwargs={})), kwargs={}, config={'run_name': 'chat_retriever_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_with_history=create_history_aware_retriever(llm_model,retriever,contextualize_q_prompt)\n",
    "retriever_with_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8888da13",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt= ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system',System_prompt),\n",
    "        MessagesPlaceholder('chat_history'),\n",
    "        ('human','{input}'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f7a9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain=create_stuff_documents_chain(llm_model,qa_prompt)\n",
    "rag_chain=create_retrieval_chain(retriever_with_history,question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "94bb9a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-reflection in AI agents refers to the process of evaluating and improving their own performance and responses. AI agents use feedback mechanisms, such as human-in-the-loop (HITL) and other AI agents, to learn from their experiences and adjust to user preferences. Through self-reflection, AI agents can refine their decision-making and prediction capabilities, enabling them to become more accurate and effective over time.\n",
      "Self-reflection in AI agents is the process of evaluating their own performance and responses. It involves using feedback mechanisms to learn from experiences and adjust to user preferences. This process is also referred to as \"learning and reflection\" in the context of AI agents.\n"
     ]
    }
   ],
   "source": [
    "chat_history=[]\n",
    "question=\"What is Self-Reflection\"\n",
    "response1=rag_chain.invoke({\"input\":question,\"chat_history\":chat_history})\n",
    "print(response1['answer'])\n",
    "\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content=response1[\"answer\"])\n",
    "    ]\n",
    ")\n",
    "\n",
    "question2=\"Tell me more about it?\"\n",
    "response2=rag_chain.invoke({\"input\":question,\"chat_history\":chat_history})\n",
    "print(response2['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "74b18bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is Self-Reflection', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Self-reflection in AI agents refers to the process of evaluating and improving their own performance and responses. AI agents use feedback mechanisms, such as human-in-the-loop (HITL) and other AI agents, to learn from their experiences and adjust to user preferences. Through self-reflection, AI agents can refine their decision-making and prediction capabilities, enabling them to become more accurate and effective over time.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c4e6d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fec1f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}\n",
    "\n",
    "def Get_Session_History(session_id: str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "conversational_rag_chain= RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    Get_Session_History,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a831b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import uuid7\n",
    "\n",
    "session_id = uuid7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fee611b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is ReWoo?',\n",
       " 'chat_history': [],\n",
       " 'context': [Document(id='fe092ccd-a365-44b8-ac24-88ac995e3eb8', metadata={}, page_content=\"ReWOO (reasoning without observation)\\nThe ReWOO method, unlike ReAct, eliminates the dependence on tool outputs for action planning. Instead, agents plan upfront. Redundant tool usage is avoided by anticipating which tools to use upon receiving the initial prompt from the user. This approach is desirable from a human-centered perspective because the user can confirm the plan before it is executed.\\nThe ReWOO workflow is made up of three modules. In the planning module, the agent anticipates its next steps given a user's prompt. The next stage entails collecting the outputs produced by calling these tools. Lastly, the agent pairs the initial plan with the tool outputs to formulate a response. This planning ahead can greatly reduce token usage and computational complexity and the repercussions of intermediate tool failure.5\\n Types of AI agents\"),\n",
       "  Document(id='70070037-dcb5-45dd-a59f-b6e537505639', metadata={}, page_content=\"ReWOO (reasoning without observation)\\nThe ReWOO method, unlike ReAct, eliminates the dependence on tool outputs for action planning. Instead, agents plan upfront. Redundant tool usage is avoided by anticipating which tools to use upon receiving the initial prompt from the user. This approach is desirable from a human-centered perspective because the user can confirm the plan before it is executed.\\nThe ReWOO workflow is made up of three modules. In the planning module, the agent anticipates its next steps given a user's prompt. The next stage entails collecting the outputs produced by calling these tools. Lastly, the agent pairs the initial plan with the tool outputs to formulate a response. This planning ahead can greatly reduce token usage and computational complexity and the repercussions of intermediate tool failure.5\\n Types of AI agents\"),\n",
       "  Document(id='6e755745-2bb2-4a1f-98cd-a1b8f9552b5c', metadata={}, page_content='AI agent orchestration\\nWhat is agent orchestration?\\nTutorial: Agent orchestration\\nCaret right\\nMulti-agent systems\\nWhat are multi-agent systems?\\nTutorial: crewAI multi-agent call analysis\\nMulti-agent collaboration\\nCaret right\\nReAct\\nWhat is ReAct?\\nTutorial: LangGraph ReAct agent\\nCaret right\\nReWOO\\nWhat is ReWOO?\\nTutorial: ReWOO reasoning agent\\nCaret right\\nProtocols\\nOverview\\nCaret right\\nAgent Communication Protocol (ACP)\\nWhat is ACP?\\nTutorial: ACP agent interoperability\\nCaret right\\nAgent2Agent (A2A) protocol\\nWhat is A2A protocol?\\nTutorial: A2A chat system\\nCaret right\\nModel Context Protocol (MCP)\\nWhat is MCP?\\nTutorial: MCP server\\nCaret right\\nMulti-agent systems\\nOverview\\nCaret right\\nAgentic orchestration\\nWhat is agentic orchestration?\\nTutorial: Agent orchestration\\nMulti-agent collaboration\\nTutorial: crewAI multi-agent call analysis\\nCaret right\\nFrameworks\\nOverview\\nCaret right\\nAutoGen\\nWhat is AutoGen?\\nTutorial: AutoGen multi-agent RAG\\nAutoGPT\\nBabyAGI\\nCaret right\\nBeeAI\\nWhat is BeeAI?'),\n",
       "  Document(id='98c08958-b670-4b8c-981f-7f138c404a5c', metadata={}, page_content='AI agent orchestration\\nWhat is agent orchestration?\\nTutorial: Agent orchestration\\nCaret right\\nMulti-agent systems\\nWhat are multi-agent systems?\\nTutorial: crewAI multi-agent call analysis\\nMulti-agent collaboration\\nCaret right\\nReAct\\nWhat is ReAct?\\nTutorial: LangGraph ReAct agent\\nCaret right\\nReWOO\\nWhat is ReWOO?\\nTutorial: ReWOO reasoning agent\\nCaret right\\nProtocols\\nOverview\\nCaret right\\nAgent Communication Protocol (ACP)\\nWhat is ACP?\\nTutorial: ACP agent interoperability\\nCaret right\\nAgent2Agent (A2A) protocol\\nWhat is A2A protocol?\\nTutorial: A2A chat system\\nCaret right\\nModel Context Protocol (MCP)\\nWhat is MCP?\\nTutorial: MCP server\\nCaret right\\nMulti-agent systems\\nOverview\\nCaret right\\nAgentic orchestration\\nWhat is agentic orchestration?\\nTutorial: Agent orchestration\\nMulti-agent collaboration\\nTutorial: crewAI multi-agent call analysis\\nCaret right\\nFrameworks\\nOverview\\nCaret right\\nAutoGen\\nWhat is AutoGen?\\nTutorial: AutoGen multi-agent RAG\\nAutoGPT\\nBabyAGI\\nCaret right\\nBeeAI\\nWhat is BeeAI?')],\n",
       " 'answer': 'ReWOO (Reasoning Without Observation) is a method that eliminates dependence on tool outputs for action planning, instead planning upfront and anticipating which tools to use. This approach allows agents to plan ahead, reducing token usage and computational complexity. ReWOO is a desirable method from a human-centered perspective as it enables users to confirm the plan before execution.'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=conversational_rag_chain.invoke({'input':\"What is ReWoo?\"},config={\"configurable\": {\"session_id\": session_id}},)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "48258e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ReWOO (Reasoning Without Observation) is a method that eliminates dependence on tool outputs for action planning, instead planning upfront and anticipating which tools to use. This approach allows agents to plan ahead, reducing token usage and computational complexity. ReWOO is a desirable method from a human-centered perspective as it enables users to confirm the plan before execution.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f7e4a34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The previous question you asked was \"What is ReWoo?\"'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=conversational_rag_chain.invoke({'input':\"What was the previous question I asked\"},config={\"configurable\": {\"session_id\": session_id}},)\n",
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "95e74cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReWOO (Reasoning Without Observation) is a method used by AI agents to plan their actions upfront, without relying on the outputs of various tools. This approach involves anticipating which tools to use and in what order, based on the initial prompt or input received from the user. The ReWOO workflow consists of three modules: \n",
      "\n",
      "1. Planning module: The agent anticipates its next steps given a user's prompt, creating an initial plan of action.\n",
      "2. Tool output collection: The agent collects the outputs produced by calling the anticipated tools.\n",
      "3. Response formulation: The agent pairs the initial plan with the tool outputs to formulate a response to the user.\n",
      "\n",
      "By planning ahead, ReWOO reduces the need for redundant tool usage, decreases token usage, and minimizes computational complexity. Additionally, it allows users to confirm the plan before it is executed, making it a desirable approach from a human-centered perspective. This method is particularly useful for complex tasks that require careful planning and execution, as it enables AI agents to make more informed and adaptive decisions.\n"
     ]
    }
   ],
   "source": [
    "response=conversational_rag_chain.invoke({'input':\"Tell more detailed description about it\"},config={\"configurable\": {\"session_id\": session_id}},)\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "523970c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know what \"agentic AI\" specifically refers to, as it is not a standard term in the provided context. However, based on the text, it appears to be related to AI systems that are autonomous and can make decisions, but I would need more information to provide a accurate description. The term \"agentic\" is mentioned in the context of \"agentic AI system\", which is designed and trained by a team of developers.\n"
     ]
    }
   ],
   "source": [
    "response=conversational_rag_chain.invoke({'input':\"What is agentic ai?\"},config={\"configurable\": {\"session_id\": session_id}},)\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4ce46a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first question you asked was \"What is ReWoo?\"'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=conversational_rag_chain.invoke({'input':\"What was the first question I asked\"},config={\"configurable\": {\"session_id\": session_id}},)\n",
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5e7eec22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{UUID('019abed1-1996-7402-b321-65643950fda5'): InMemoryChatMessageHistory(messages=[HumanMessage(content='What is ReWoo?', additional_kwargs={}, response_metadata={}), AIMessage(content='ReWOO (Reasoning Without Observation) is a method that eliminates dependence on tool outputs for action planning, instead planning upfront and anticipating which tools to use. This approach allows agents to plan ahead, reducing token usage and computational complexity. ReWOO is a desirable method from a human-centered perspective as it enables users to confirm the plan before execution.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What was the previous question I asked', additional_kwargs={}, response_metadata={}), AIMessage(content='The previous question you asked was \"What is ReWoo?\"', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell more detailed description about it', additional_kwargs={}, response_metadata={}), AIMessage(content=\"ReWOO (Reasoning Without Observation) is a method used by AI agents to plan their actions upfront, without relying on the outputs of various tools. This approach involves anticipating which tools to use and in what order, based on the initial prompt or input received from the user. The ReWOO workflow consists of three modules: \\n\\n1. Planning module: The agent anticipates its next steps given a user's prompt, creating an initial plan of action.\\n2. Tool output collection: The agent collects the outputs produced by calling the anticipated tools.\\n3. Response formulation: The agent pairs the initial plan with the tool outputs to formulate a response to the user.\\n\\nBy planning ahead, ReWOO reduces the need for redundant tool usage, decreases token usage, and minimizes computational complexity. Additionally, it allows users to confirm the plan before it is executed, making it a desirable approach from a human-centered perspective. This method is particularly useful for complex tasks that require careful planning and execution, as it enables AI agents to make more informed and adaptive decisions.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is agentic ai?', additional_kwargs={}, response_metadata={}), AIMessage(content='I don\\'t know what \"agentic AI\" specifically refers to, as it is not a standard term in the provided context. However, based on the text, it appears to be related to AI systems that are autonomous and can make decisions, but I would need more information to provide a accurate description. The term \"agentic\" is mentioned in the context of \"agentic AI system\", which is designed and trained by a team of developers.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What was the first question I asked', additional_kwargs={}, response_metadata={}), AIMessage(content='The first question you asked was \"What is ReWoo?\"', additional_kwargs={}, response_metadata={})])}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ae7513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
