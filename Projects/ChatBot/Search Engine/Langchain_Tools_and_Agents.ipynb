{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e3ab5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['GROQ_API_KEY']=os.getenv('GROQ_API_KEY')\n",
    "Groq_api_key=os.getenv('GROQ_API_KEY')\n",
    "os.environ['HF_API_KEY']=os.getenv('HF_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb26bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ca29ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wikipedia\n",
    "wikipedia_api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=500)\n",
    "wiki=WikipediaQueryRun(api_wrapper=wikipedia_api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9442d95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2bc20e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Arxiv\n",
    "arxiv_api_wrapper=ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=250)\n",
    "arxiv=ArxivQueryRun(api_wrapper=arxiv_api_wrapper)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3ee76b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[wiki,arxiv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "535e5721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "#creating custom rag tools\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18efdd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=WebBaseLoader('https://docs.smith.langchain.com/')\n",
    "docs=loader.load()\n",
    "splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "Documents=splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e848dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x12f4e2950>, search_kwargs={})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embeddings=HuggingFaceEmbeddings(model=\"all-MiniLM-L6-v2\")\n",
    "vectordb=FAISS.from_documents(documents=Documents,embedding=Embeddings)\n",
    "retriever=vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9179fc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='langsmith_search', description='search any information about langsmith', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x12e5a6050>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x12f4e2950>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x12f6c1000>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x12f4e2950>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_classic.tools.retriever import create_retriever_tool\n",
    "retriever_tool=create_retriever_tool(retriever,'langsmith_search','search any information about langsmith')\n",
    "retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3de0df66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith_search'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1271bb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/opt/homebrew/lib/python3.10/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=500)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)),\n",
       " Tool(name='langsmith_search', description='search any information about langsmith', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x12e5a6050>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x12f4e2950>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x12f6c1000>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x12f4e2950>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools=[wiki,arxiv,retriever_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6db9110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running this tools with agents and llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48e97fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import openai\n",
    "\n",
    "llm_model=ChatGroq(groq_api_key=Groq_api_key,model=\"openai/gpt-oss-120b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b77e10de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_classic import hub\n",
    "prompt=hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0262439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x10e8e2ef0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x10e8e2ef0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x130c11a50>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x130c11960>, model_name='openai/gpt-oss-120b', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith_search', 'description': 'search any information about langsmith', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_classic.agents import create_openai_tools_agent,AgentExecutor\n",
    "Agent=create_openai_tools_agent(llm_model,tools,prompt)\n",
    "Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "737ba72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x10e8e2ef0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x10e8e2ef0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x130c11a50>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x130c11960>, model_name='openai/gpt-oss-120b', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith_search', 'description': 'search any information about langsmith', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/opt/homebrew/lib/python3.10/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=500)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)), Tool(name='langsmith_search', description='search any information about langsmith', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x12e5a6050>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x12f4e2950>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x12f6c1000>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x12f4e2950>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor=AgentExecutor(agent=Agent,tools=tools,verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd73dc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'LangChain'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m**LangChain** is an open‑source software framework designed to make it easier to build applications that incorporate large language models (LLMs) such as OpenAI’s GPT‑4, Anthropic’s Claude, or LLaMA.  \n",
      "\n",
      "### Core Idea\n",
      "Instead of treating an LLM as a stand‑alone “black box,” LangChain provides a set of building blocks that let developers **chain together** LLM calls with other components (data sources, prompts, memory, agents, etc.) to create richer, more interactive systems.\n",
      "\n",
      "### Main Building Blocks\n",
      "| Block | What it does | Typical use |\n",
      "|-------|--------------|------------|\n",
      "| **Prompt Templates** | Standardizes and parameterizes prompt creation | Re‑using prompts across tasks, injecting variables |\n",
      "| **LLM Wrappers** | Uniform API for different LLM providers (OpenAI, Azure, Anthropic, HuggingFace, etc.) | Swap models without changing code |\n",
      "| **Chains** | Sequential or parallel composition of LLM calls and other utilities | “Summarize → translate → store” pipelines |\n",
      "| **Agents** | LLMs that can decide which tool to call next (search, calculator, DB query) | Autonomous assistants, self‑routing chatbots |\n",
      "| **Memory** | Persists conversation context across turns | Chatbots that remember prior user inputs |\n",
      "| **Retrievers / Vector Stores** | Connects LLMs to external knowledge bases (e.g., Pinecone, Weaviate, FAISS) | Retrieval‑augmented generation (RAG) for up‑to‑date facts |\n",
      "| **Callbacks / Tracing** | Hooks for logging, debugging, and observability | Monitoring token usage, latency, errors |\n",
      "| **Integrations** | Connectors for APIs, databases, file systems, web scraping, etc. | Pulling data from a CRM, crawling a website, reading PDFs |\n",
      "\n",
      "### Typical Use Cases\n",
      "- **Retrieval‑augmented generation (RAG):** Combine a vector‑store of documents with an LLM to answer questions with up‑to‑date, source‑grounded information.  \n",
      "- **Chatbots & virtual assistants:** Build conversational agents that keep context, call external tools (e.g., calendar, email), and follow complex workflows.  \n",
      "- **Document processing:** Summarize, extract entities, or translate large collections of PDFs, emails, or code.  \n",
      "- **Code analysis & generation:** Prompt LLMs to review, refactor, or write code, optionally feeding back test results.  \n",
      "- **Data analysis:** Use LLMs to generate SQL queries, interpret results, or produce natural‑language reports from raw data.\n",
      "\n",
      "### Why Use LangChain?\n",
      "1. **Modularity:** You can pick only the pieces you need (e.g., just the Retrieval component) and swap implementations without rewriting the whole app.  \n",
      "2. **Rapid prototyping:** High‑level abstractions let you go from idea to a working prototype in minutes.  \n",
      "3. **Scalability & Observability:** Built‑in callbacks, tracing, and async support help move from a notebook demo to production‑grade services.  \n",
      "4. **Community & Ecosystem:** A vibrant open‑source community contributes integrations (vector DBs, APIs, UI tools) and maintains extensive documentation and example notebooks.\n",
      "\n",
      "### Getting Started (Python example)\n",
      "```python\n",
      "from langchain import OpenAI, PromptTemplate, LLMChain\n",
      "from langchain.chains import RetrievalQA\n",
      "from langchain.vectorstores import FAISS\n",
      "from langchain.embeddings import OpenAIEmbeddings\n",
      "\n",
      "# 1. Load a vector store with your documents\n",
      "embeddings = OpenAIEmbeddings()\n",
      "vector_store = FAISS.from_texts(docs, embeddings)\n",
      "\n",
      "# 2. Set up a retriever\n",
      "retriever = vector_store.as_retriever(search_kwargs={\"k\": 4})\n",
      "\n",
      "# 3. Create a QA chain that uses the retriever + LLM\n",
      "qa = RetrievalQA.from_chain_type(\n",
      "    llm=OpenAI(model=\"gpt-4\"),\n",
      "    chain_type=\"stuff\",\n",
      "    retriever=retriever,\n",
      ")\n",
      "\n",
      "# 4. Ask a question\n",
      "answer = qa.run(\"What are the main challenges of quantum computing?\")\n",
      "print(answer)\n",
      "```\n",
      "This snippet shows the classic RAG pattern: **documents → embeddings → vector store → retriever → LLM → answer**.\n",
      "\n",
      "### Ecosystem Extensions\n",
      "- **LangServe:** A lightweight server for deploying LangChain apps as HTTP endpoints.  \n",
      "- **LangGraph:** A newer library for building more complex, stateful workflows (graphs) on top of LangChain.  \n",
      "- **LangSmith (formerly LangChain‑Hub):** A platform for experiment tracking, prompt versioning, and evaluation of LLM‑based pipelines.\n",
      "\n",
      "---\n",
      "\n",
      "**In short:** LangChain is a modular framework that abstracts away the plumbing needed to combine LLMs with prompts, external data, memory, and tools, enabling developers to build sophisticated AI‑augmented applications quickly and reliably.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is langchain',\n",
       " 'output': '**LangChain** is an open‑source software framework designed to make it easier to build applications that incorporate large language models (LLMs) such as OpenAI’s GPT‑4, Anthropic’s Claude, or LLaMA.  \\n\\n### Core Idea\\nInstead of treating an LLM as a stand‑alone “black box,” LangChain provides a set of building blocks that let developers **chain together** LLM calls with other components (data sources, prompts, memory, agents, etc.) to create richer, more interactive systems.\\n\\n### Main Building Blocks\\n| Block | What it does | Typical use |\\n|-------|--------------|------------|\\n| **Prompt Templates** | Standardizes and parameterizes prompt creation | Re‑using prompts across tasks, injecting variables |\\n| **LLM Wrappers** | Uniform API for different LLM providers (OpenAI, Azure, Anthropic, HuggingFace, etc.) | Swap models without changing code |\\n| **Chains** | Sequential or parallel composition of LLM calls and other utilities | “Summarize → translate → store” pipelines |\\n| **Agents** | LLMs that can decide which tool to call next (search, calculator, DB query) | Autonomous assistants, self‑routing chatbots |\\n| **Memory** | Persists conversation context across turns | Chatbots that remember prior user inputs |\\n| **Retrievers / Vector Stores** | Connects LLMs to external knowledge bases (e.g., Pinecone, Weaviate, FAISS) | Retrieval‑augmented generation (RAG) for up‑to‑date facts |\\n| **Callbacks / Tracing** | Hooks for logging, debugging, and observability | Monitoring token usage, latency, errors |\\n| **Integrations** | Connectors for APIs, databases, file systems, web scraping, etc. | Pulling data from a CRM, crawling a website, reading PDFs |\\n\\n### Typical Use Cases\\n- **Retrieval‑augmented generation (RAG):** Combine a vector‑store of documents with an LLM to answer questions with up‑to‑date, source‑grounded information.  \\n- **Chatbots & virtual assistants:** Build conversational agents that keep context, call external tools (e.g., calendar, email), and follow complex workflows.  \\n- **Document processing:** Summarize, extract entities, or translate large collections of PDFs, emails, or code.  \\n- **Code analysis & generation:** Prompt LLMs to review, refactor, or write code, optionally feeding back test results.  \\n- **Data analysis:** Use LLMs to generate SQL queries, interpret results, or produce natural‑language reports from raw data.\\n\\n### Why Use LangChain?\\n1. **Modularity:** You can pick only the pieces you need (e.g., just the Retrieval component) and swap implementations without rewriting the whole app.  \\n2. **Rapid prototyping:** High‑level abstractions let you go from idea to a working prototype in minutes.  \\n3. **Scalability & Observability:** Built‑in callbacks, tracing, and async support help move from a notebook demo to production‑grade services.  \\n4. **Community & Ecosystem:** A vibrant open‑source community contributes integrations (vector DBs, APIs, UI tools) and maintains extensive documentation and example notebooks.\\n\\n### Getting Started (Python example)\\n```python\\nfrom langchain import OpenAI, PromptTemplate, LLMChain\\nfrom langchain.chains import RetrievalQA\\nfrom langchain.vectorstores import FAISS\\nfrom langchain.embeddings import OpenAIEmbeddings\\n\\n# 1. Load a vector store with your documents\\nembeddings = OpenAIEmbeddings()\\nvector_store = FAISS.from_texts(docs, embeddings)\\n\\n# 2. Set up a retriever\\nretriever = vector_store.as_retriever(search_kwargs={\"k\": 4})\\n\\n# 3. Create a QA chain that uses the retriever + LLM\\nqa = RetrievalQA.from_chain_type(\\n    llm=OpenAI(model=\"gpt-4\"),\\n    chain_type=\"stuff\",\\n    retriever=retriever,\\n)\\n\\n# 4. Ask a question\\nanswer = qa.run(\"What are the main challenges of quantum computing?\")\\nprint(answer)\\n```\\nThis snippet shows the classic RAG pattern: **documents → embeddings → vector store → retriever → LLM → answer**.\\n\\n### Ecosystem Extensions\\n- **LangServe:** A lightweight server for deploying LangChain apps as HTTP endpoints.  \\n- **LangGraph:** A newer library for building more complex, stateful workflows (graphs) on top of LangChain.  \\n- **LangSmith (formerly LangChain‑Hub):** A platform for experiment tracking, prompt versioning, and evaluation of LLM‑based pipelines.\\n\\n---\\n\\n**In short:** LangChain is a modular framework that abstracts away the plumbing needed to combine LLMs with prompts, external data, memory, and tools, enabling developers to build sophisticated AI‑augmented applications quickly and reliably.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({'input':'What is langchain'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e4c2e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Agentic AI'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Agentic AI\n",
      "Summary: In the context of generative artificial intelligence, AI agents (also referred to as compound AI systems or agentic AI) are a class of intelligent agents distinguished by their ability to operate autonomously in complex environments. Agentic AI tools prioritize decision-making over content creation and do not require human prompts or continuous oversight.\n",
      "\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m**Agentic AI** (also called *agentic artificial intelligence*, *AI agents*, or *compound AI systems*) refers to a class of generative‑AI‑driven software agents that are designed to **act autonomously** in complex, often open‑ended environments.  \n",
      "\n",
      "---\n",
      "\n",
      "## Core Characteristics\n",
      "\n",
      "| Feature | What it means for an Agentic AI |\n",
      "|---------|---------------------------------|\n",
      "| **Autonomy** | The system can initiate actions, make decisions, and pursue goals without a human issuing a new prompt for each step. |\n",
      "| **Goal‑oriented behavior** | It is equipped with explicit or learned objectives (e.g., “find the cheapest flight”, “optimize a supply‑chain schedule”) and plans a sequence of actions to achieve them. |\n",
      "| **Perception‑Action loop** | It continuously observes its environment (via APIs, sensors, web data, etc.), updates an internal state, and selects the next action. |\n",
      "| **Tool use** | It can invoke external tools—web browsers, databases, code interpreters, robotic controllers—by calling APIs or executing code. |\n",
      "| **Memory & reasoning** | Many implementations maintain short‑term or long‑term memory (e.g., vector stores, knowledge graphs) and use chain‑of‑thought or other reasoning patterns to chain together multiple steps. |\n",
      "| **Self‑improvement (optional)** | Some designs allow the agent to refine its own prompts, policies, or even generate new sub‑agents to handle sub‑tasks. |\n",
      "| **Minimal human prompting** | After an initial high‑level instruction (“plan a weekend trip to Paris”), the agent proceeds without needing a step‑by‑step prompt from a user. |\n",
      "\n",
      "---\n",
      "\n",
      "## How It Differs From Conventional Generative AI\n",
      "\n",
      "| Conventional Generative AI (e.g., ChatGPT) | Agentic AI |\n",
      "|--------------------------------------------|------------|\n",
      "| **Prompt‑driven** – each response is directly triggered by a user’s text. | **Decision‑driven** – the system decides when to act, what to ask, and which tools to invoke. |\n",
      "| Produces **content** (text, images, code) as the primary output. | Produces **actions** (API calls, database queries, robot commands) as the primary output. |\n",
      "| Usually **stateless** between turns (unless explicitly given a conversation history). | Maintains **state/memory** across many interactions and can plan multi‑step procedures. |\n",
      "| Limited to the context window of the model. | Can extend its capabilities by chaining external tools, storing results, and iterating indefinitely. |\n",
      "\n",
      "---\n",
      "\n",
      "## Typical Architecture\n",
      "\n",
      "1. **Goal Specification** – a high‑level user request or a programmed objective.  \n",
      "2. **Planner / Policy** – a language model (or reinforcement‑learning policy) that decides the next action based on the current state.  \n",
      "3. **Tool Interface Layer** – adapters that let the planner call external services (search engines, code interpreters, robotics APIs, etc.).  \n",
      "4. **Memory Store** – vector databases, key‑value stores, or structured knowledge bases that preserve context across steps.  \n",
      "5. **Feedback Loop** – the result of each tool call is fed back to the planner, allowing it to refine its next move.  \n",
      "\n",
      "A popular concrete example is **Auto‑GPT**, where GPT‑4 is used as the planner and it can invoke a set of “tools” (web search, file system, Python execution) to accomplish tasks like “write a market‑analysis report”.\n",
      "\n",
      "---\n",
      "\n",
      "## Real‑World Use Cases\n",
      "\n",
      "| Domain | Example Agentic AI Application |\n",
      "|--------|--------------------------------|\n",
      "| **Productivity** | An AI that drafts a proposal, gathers data from internal databases, creates a slide deck, and emails it to stakeholders—all from a single “write a proposal” command. |\n",
      "| **Customer Support** | An autonomous bot that diagnoses a user’s issue, checks the ticketing system, escalates to a human if needed, and follows up with a resolution email. |\n",
      "| **Finance** | An agent that monitors market data, rebalances a portfolio, generates compliance reports, and notifies the portfolio manager. |\n",
      "| **Robotics** | A robot that perceives its surroundings, plans a navigation path, manipulates objects, and adapts to unexpected obstacles without human tele‑operation. |\n",
      "| **Research & Data Mining** | An AI that searches scholarly databases, extracts relevant papers, summarizes findings, and drafts a literature review. |\n",
      "\n",
      "---\n",
      "\n",
      "## Benefits\n",
      "\n",
      "* **Scalability** – One high‑level instruction can trigger a cascade of automated actions, reducing manual effort.  \n",
      "* **Speed** – Continuous, programmatic decision making can outperform humans in repetitive or data‑intensive tasks.  \n",
      "* **Adaptability** – By integrating external tools, agents can operate in domains where the base language model lacks direct knowledge.  \n",
      "* **End‑to‑end automation** – From goal definition to execution and reporting, the whole workflow can be closed‑loop.\n",
      "\n",
      "---\n",
      "\n",
      "## Risks & Challenges\n",
      "\n",
      "| Concern | Why it matters |\n",
      "|---------|----------------|\n",
      "| **Loss of human oversight** | Autonomous actions may produce unintended side effects (e.g., erroneous trades, privacy violations). |\n",
      "| **Hallucination in planning** | If the language‑model planner fabricates tool calls or misinterprets results, the agent can go off‑track. |\n",
      "| **Security** | Allowing an AI to invoke arbitrary APIs or execute code can be a vector for abuse if not sandboxed. |\n",
      "| **Accountability** | Determining who is responsible for an autonomous decision (the user, the developer, the model provider) is still an open legal/ethical question. |\n",
      "| **Resource consumption** | Multi‑step loops can be compute‑intensive, especially when each step involves large‑scale models or external services. |\n",
      "\n",
      "Mitigations include **human‑in‑the‑loop checkpoints**, **sandboxed tool execution**, **audit logs**, and **robust verification of tool outputs**.\n",
      "\n",
      "---\n",
      "\n",
      "## Emerging Trends\n",
      "\n",
      "1. **Hybrid agents** that combine **reinforcement learning** policies with **LLM‑based reasoning** to improve reliability.  \n",
      "2. **Self‑prompting loops** where the agent rewrites its own prompts to better align with the task.  \n",
      "3. **Multi‑agent ecosystems** where several specialized agents coordinate (e.g., a planner, a data‑retriever, and an executor).  \n",
      "4. **Standardized tool‑calling APIs** (e.g., OpenAI’s “function calling”, Anthropic’s “tool use”) that make it easier to plug in external capabilities.  \n",
      "\n",
      "---\n",
      "\n",
      "### TL;DR\n",
      "\n",
      "**Agentic AI** is a generation of AI systems that go beyond generating text or images; they **act**. By continuously perceiving their environment, maintaining memory, and invoking external tools, they can autonomously pursue complex goals with minimal human prompting. This opens powerful automation possibilities but also introduces new safety, governance, and technical challenges that must be addressed as the technology matures.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is Agentic Ai',\n",
       " 'output': '**Agentic AI** (also called *agentic artificial intelligence*, *AI agents*, or *compound AI systems*) refers to a class of generative‑AI‑driven software agents that are designed to **act autonomously** in complex, often open‑ended environments.  \\n\\n---\\n\\n## Core Characteristics\\n\\n| Feature | What it means for an Agentic AI |\\n|---------|---------------------------------|\\n| **Autonomy** | The system can initiate actions, make decisions, and pursue goals without a human issuing a new prompt for each step. |\\n| **Goal‑oriented behavior** | It is equipped with explicit or learned objectives (e.g., “find the cheapest flight”, “optimize a supply‑chain schedule”) and plans a sequence of actions to achieve them. |\\n| **Perception‑Action loop** | It continuously observes its environment (via APIs, sensors, web data, etc.), updates an internal state, and selects the next action. |\\n| **Tool use** | It can invoke external tools—web browsers, databases, code interpreters, robotic controllers—by calling APIs or executing code. |\\n| **Memory & reasoning** | Many implementations maintain short‑term or long‑term memory (e.g., vector stores, knowledge graphs) and use chain‑of‑thought or other reasoning patterns to chain together multiple steps. |\\n| **Self‑improvement (optional)** | Some designs allow the agent to refine its own prompts, policies, or even generate new sub‑agents to handle sub‑tasks. |\\n| **Minimal human prompting** | After an initial high‑level instruction (“plan a weekend trip to Paris”), the agent proceeds without needing a step‑by‑step prompt from a user. |\\n\\n---\\n\\n## How It Differs From Conventional Generative AI\\n\\n| Conventional Generative AI (e.g., ChatGPT) | Agentic AI |\\n|--------------------------------------------|------------|\\n| **Prompt‑driven** – each response is directly triggered by a user’s text. | **Decision‑driven** – the system decides when to act, what to ask, and which tools to invoke. |\\n| Produces **content** (text, images, code) as the primary output. | Produces **actions** (API calls, database queries, robot commands) as the primary output. |\\n| Usually **stateless** between turns (unless explicitly given a conversation history). | Maintains **state/memory** across many interactions and can plan multi‑step procedures. |\\n| Limited to the context window of the model. | Can extend its capabilities by chaining external tools, storing results, and iterating indefinitely. |\\n\\n---\\n\\n## Typical Architecture\\n\\n1. **Goal Specification** – a high‑level user request or a programmed objective.  \\n2. **Planner / Policy** – a language model (or reinforcement‑learning policy) that decides the next action based on the current state.  \\n3. **Tool Interface Layer** – adapters that let the planner call external services (search engines, code interpreters, robotics APIs, etc.).  \\n4. **Memory Store** – vector databases, key‑value stores, or structured knowledge bases that preserve context across steps.  \\n5. **Feedback Loop** – the result of each tool call is fed back to the planner, allowing it to refine its next move.  \\n\\nA popular concrete example is **Auto‑GPT**, where GPT‑4 is used as the planner and it can invoke a set of “tools” (web search, file system, Python execution) to accomplish tasks like “write a market‑analysis report”.\\n\\n---\\n\\n## Real‑World Use Cases\\n\\n| Domain | Example Agentic AI Application |\\n|--------|--------------------------------|\\n| **Productivity** | An AI that drafts a proposal, gathers data from internal databases, creates a slide deck, and emails it to stakeholders—all from a single “write a proposal” command. |\\n| **Customer Support** | An autonomous bot that diagnoses a user’s issue, checks the ticketing system, escalates to a human if needed, and follows up with a resolution email. |\\n| **Finance** | An agent that monitors market data, rebalances a portfolio, generates compliance reports, and notifies the portfolio manager. |\\n| **Robotics** | A robot that perceives its surroundings, plans a navigation path, manipulates objects, and adapts to unexpected obstacles without human tele‑operation. |\\n| **Research & Data Mining** | An AI that searches scholarly databases, extracts relevant papers, summarizes findings, and drafts a literature review. |\\n\\n---\\n\\n## Benefits\\n\\n* **Scalability** – One high‑level instruction can trigger a cascade of automated actions, reducing manual effort.  \\n* **Speed** – Continuous, programmatic decision making can outperform humans in repetitive or data‑intensive tasks.  \\n* **Adaptability** – By integrating external tools, agents can operate in domains where the base language model lacks direct knowledge.  \\n* **End‑to‑end automation** – From goal definition to execution and reporting, the whole workflow can be closed‑loop.\\n\\n---\\n\\n## Risks & Challenges\\n\\n| Concern | Why it matters |\\n|---------|----------------|\\n| **Loss of human oversight** | Autonomous actions may produce unintended side effects (e.g., erroneous trades, privacy violations). |\\n| **Hallucination in planning** | If the language‑model planner fabricates tool calls or misinterprets results, the agent can go off‑track. |\\n| **Security** | Allowing an AI to invoke arbitrary APIs or execute code can be a vector for abuse if not sandboxed. |\\n| **Accountability** | Determining who is responsible for an autonomous decision (the user, the developer, the model provider) is still an open legal/ethical question. |\\n| **Resource consumption** | Multi‑step loops can be compute‑intensive, especially when each step involves large‑scale models or external services. |\\n\\nMitigations include **human‑in‑the‑loop checkpoints**, **sandboxed tool execution**, **audit logs**, and **robust verification of tool outputs**.\\n\\n---\\n\\n## Emerging Trends\\n\\n1. **Hybrid agents** that combine **reinforcement learning** policies with **LLM‑based reasoning** to improve reliability.  \\n2. **Self‑prompting loops** where the agent rewrites its own prompts to better align with the task.  \\n3. **Multi‑agent ecosystems** where several specialized agents coordinate (e.g., a planner, a data‑retriever, and an executor).  \\n4. **Standardized tool‑calling APIs** (e.g., OpenAI’s “function calling”, Anthropic’s “tool use”) that make it easier to plug in external capabilities.  \\n\\n---\\n\\n### TL;DR\\n\\n**Agentic AI** is a generation of AI systems that go beyond generating text or images; they **act**. By continuously perceiving their environment, maintaining memory, and invoking external tools, they can autonomously pursue complex goals with minimal human prompting. This opens powerful automation possibilities but also introduces new safety, governance, and technical challenges that must be addressed as the technology matures.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({'input':'What is Agentic Ai'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40229336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Mohanlal'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Mohanlal\n",
      "Summary: Mohanlal Viswanathan (IPA: [moːhɐnlaːl ʋiʃʋʷɐn̪aːt̪ʰɐn]; born 21 May 1960), known mononymously as Mohanlal, is an Indian actor and filmmaker who predominantly works in Malayalam cinema and has also occasionally appeared in Tamil, Hindi, Telugu and Kannada films. Mohanlal has a prolific career spanning over four decades, during which he has acted in more than 400 films. The Government of India honoured him with Padma Shri in 2001 and Padma Bhushan in 2019, India's fourth a\u001b[0m\u001b[32;1m\u001b[1;3mMohanlal Viswanathan (born 21 May 1960) is a celebrated Indian actor, filmmaker, and occasional playback singer who works primarily in Malayalam cinema, though he has also appeared in Tamil, Hindi, Telugu and Kannada films. Often referred to simply as “Mohanlal,” he began his career in the late 1970s and has since acted in more than 400 movies across a span of over four decades, earning a reputation for his versatility, naturalistic style, and ability to portray a wide range of characters—from intense dramatic roles to comic performances.\n",
      "\n",
      "**Key highlights of his life and career**\n",
      "\n",
      "| Aspect | Details |\n",
      "|--------|---------|\n",
      "| **Birthplace** | Elanthoor, Kerala, India |\n",
      "| **Debut** | “Thiranottam” (filmed 1978, released 2005) – first released film was “Manjil Virinja Pookkal” (1980) |\n",
      "| **Major awards** | 9 National Film Awards (including Best Actor for *Vanaprastham*, *Bharatham*, *Kaalapani*), 14 Kerala State Film Awards, 5 Filmfare Awards South, 2 Padma awards (Padma Shri 2001, Padma Bhushan 2019) |\n",
      "| **Notable films** | *Kireedam*, *Bharatham*, *Vanaprastham*, *Chithram*, *Naran*, *Drishyam*, *Pulimurugan*, *Iruvar* (Tamil), *Kamal Haasan’s “Minsara Kanavu”* (Tamil), *“Maqbool”* (Hindi) |\n",
      "| **Other roles** | Film producer, director (e.g., *Iruvar* – co‑director), playback singer, and occasional television host |\n",
      "| **Cultural impact** | Widely regarded as one of the greatest actors in Indian cinema; a cultural icon in Kerala and among the Malayalam diaspora worldwide. |\n",
      "\n",
      "Mohanlal’s contributions have not only shaped the Malayalam film industry but have also earned him recognition across Indian cinema at large. His enduring popularity, prolific output, and the critical acclaim he consistently receives make him a pivotal figure in contemporary Indian arts and entertainment.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Who is Mohanlal',\n",
       " 'output': 'Mohanlal\\u202fViswanathan (born\\u202f21\\u202fMay\\u202f1960) is a celebrated Indian actor, filmmaker, and occasional playback singer who works primarily in Malayalam cinema, though he has also appeared in Tamil, Hindi, Telugu and Kannada films.\\u202fOften referred to simply as “Mohanlal,” he began his career in the late 1970s and has since acted in more than\\u202f400\\u202fmovies across a span of over four decades, earning a reputation for his versatility, naturalistic style, and ability to portray a wide range of characters—from intense dramatic roles to comic performances.\\n\\n**Key highlights of his life and career**\\n\\n| Aspect | Details |\\n|--------|---------|\\n| **Birthplace** | Elanthoor, Kerala, India |\\n| **Debut** | “Thiranottam” (filmed 1978, released 2005) – first released film was “Manjil Virinja Pookkal” (1980) |\\n| **Major awards** | 9\\u202fNational Film Awards (including Best Actor for *Vanaprastham*, *Bharatham*, *Kaalapani*), 14\\u202fKerala State Film Awards, 5\\u202fFilmfare Awards South, 2\\u202fPadma awards (Padma\\u202fShri\\u202f2001, Padma\\u202fBhushan\\u202f2019) |\\n| **Notable films** | *Kireedam*, *Bharatham*, *Vanaprastham*, *Chithram*, *Naran*, *Drishyam*, *Pulimurugan*, *Iruvar* (Tamil), *Kamal Haasan’s “Minsara Kanavu”* (Tamil), *“Maqbool”* (Hindi) |\\n| **Other roles** | Film producer, director (e.g., *Iruvar* – co‑director), playback singer, and occasional television host |\\n| **Cultural impact** | Widely regarded as one of the greatest actors in Indian cinema; a cultural icon in Kerala and among the Malayalam diaspora worldwide. |\\n\\nMohanlal’s contributions have not only shaped the Malayalam film industry but have also earned him recognition across Indian cinema at large. His enduring popularity, prolific output, and the critical acclaim he consistently receives make him a pivotal figure in contemporary Indian arts and entertainment.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({'input':'Who is Mohanlal'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1df85c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
